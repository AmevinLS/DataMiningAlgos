{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cmp_to_key\n",
    "def _itemset_str_comparator(a:str, b: str):\n",
    "        if len(a) < len(b):\n",
    "            return -1\n",
    "        if len(a) > len(b):\n",
    "            return 1\n",
    "\n",
    "        if a < b:\n",
    "            return -1\n",
    "        if a > b:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AprioriSolver:\n",
    "    def __init__(self, data: list, minsup: int):\n",
    "        self.data = [set(str(x)) for x in data]\n",
    "        self.minsup = minsup\n",
    "        self._unique_attributes = set.union(*self.data)\n",
    "\n",
    "    def _support(self, itemset: set):\n",
    "        res = 0\n",
    "        for transaction in self.data:\n",
    "            if itemset.issubset(transaction):\n",
    "                res += 1\n",
    "        return res\n",
    "\n",
    "    def _freq_itemsets_bruteforce(self, size=1):\n",
    "        res = []\n",
    "        for combo in combinations(self._unique_attributes, size):\n",
    "            itemset = set(combo)\n",
    "            if self._support(itemset) >= self.minsup:\n",
    "                res.append(itemset)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def apriori_gen(self, L_k1, k):\n",
    "        C_k = []\n",
    "        for p in L_k1:\n",
    "            for q in L_k1:\n",
    "                if k > 2 and list(p)[:k-2] != list(q)[:k-2]:\n",
    "                    continue\n",
    "                if k > 1 and list(p)[k-2] >= list(q)[k-2]:\n",
    "                    continue\n",
    "                C_k.append(set.union(p, q))\n",
    "\n",
    "        bad_cs = []\n",
    "        for c in C_k:\n",
    "            for item in c:\n",
    "                subset = c.difference({item})\n",
    "                if subset not in L_k1:\n",
    "                    bad_cs.append(c)\n",
    "\n",
    "        for bad_c in bad_cs:\n",
    "            C_k.remove(bad_c)\n",
    "\n",
    "        return C_k\n",
    "\n",
    "    def apriori(self, verbose=False):\n",
    "        L = [None, self._freq_itemsets_bruteforce()]\n",
    "        C = [None, [{x} for x in self._unique_attributes]]\n",
    "        k = 2\n",
    "        while len(L[k-1]) > 0:\n",
    "            C_k = self.apriori_gen(L[k-1], k)\n",
    "            L_k = []\n",
    "\n",
    "            for c in C_k:\n",
    "                if self._support(c) >= self.minsup:\n",
    "                    L_k.append(c)\n",
    "\n",
    "            L.append(L_k)\n",
    "            C.append(C_k)\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        self.Ls = L\n",
    "        self.Cs = C\n",
    "\n",
    "    def print_report(self):\n",
    "        print(\"Main Apriori Process:\")\n",
    "        for i in range(1, len(self.Ls)):\n",
    "            C_dict, L_dict = dict(), dict()\n",
    "            for c in self.Cs[i]:\n",
    "                C_dict[\"\".join(sorted(c))] = self._support(c)\n",
    "            for l in self.Ls[i]:\n",
    "                L_dict[\"\".join(sorted(l))] = self._support(l)\n",
    "\n",
    "            keys = list(sorted(C_dict.keys()))\n",
    "            C_dict = {key: C_dict[key] for key in keys}\n",
    "\n",
    "            keys = list(sorted(L_dict.keys()))\n",
    "            L_dict = {key: L_dict[key] for key in keys}\n",
    "\n",
    "            print(f\"C{i}: {C_dict}\")\n",
    "            print(f\"L{i}: {L_dict}\")\n",
    "            print(\"=============\")\n",
    "\n",
    "    def _format_itemset_list_as_dict(self, l: list):\n",
    "        res_dict = dict()\n",
    "        for c in l:\n",
    "            res_dict[\"\".join(sorted(c))] = self._support(c)\n",
    "\n",
    "        keys = list(sorted(res_dict.keys(), key=_itemset_str_comparator))\n",
    "        res_dict = {key: res_dict[key] for key in keys}\n",
    "        return res_dict\n",
    "\n",
    "    def _is_superset_in_list(self, s: set, l: list):\n",
    "        for elem in l:\n",
    "            if elem.issuperset(s):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_maximal_frequent(self):\n",
    "        result = []\n",
    "        for i in range(1, len(self.Ls)-1):\n",
    "            for itemset in self.Ls[i]:\n",
    "                if not self._is_superset_in_list(itemset, self.Ls[i+1]):\n",
    "                    result.append(itemset)\n",
    "        result.extend(self.Ls[-1])\n",
    "        result = self._format_itemset_list_as_dict(result)\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def get_closed_frequent(self):\n",
    "        result = []\n",
    "        for i in range(1, len(self.Ls)-1):\n",
    "            for itemset in self.Ls[i]:\n",
    "                good = True\n",
    "                for upper in self.Ls[i+1]:\n",
    "                    if upper.issuperset(itemset) and self._support(itemset) == self._support(upper):\n",
    "                        good = False\n",
    "                        break\n",
    "                if good:\n",
    "                    result.append(itemset)\n",
    "        result.extend(self.Ls[-1])\n",
    "        result = self._format_itemset_list_as_dict(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Apriori Process:\n",
      "C1: {'A': 4, 'B': 6, 'C': 4, 'D': 4, 'E': 5}\n",
      "L1: {'A': 4, 'B': 6, 'C': 4, 'D': 4, 'E': 5}\n",
      "=============\n",
      "C2: {'AB': 4, 'AC': 2, 'AD': 3, 'AE': 4, 'BC': 4, 'BD': 4, 'BE': 5, 'CD': 2, 'CE': 3, 'DE': 3}\n",
      "L2: {'AB': 4, 'AC': 2, 'AD': 3, 'AE': 4, 'BC': 4, 'BD': 4, 'BE': 5, 'CD': 2, 'CE': 3, 'DE': 3}\n",
      "=============\n",
      "C3: {'ABC': 2, 'ABD': 3, 'ABE': 4, 'ACD': 1, 'ACE': 2, 'ADE': 3, 'BCD': 2, 'BCE': 3, 'BDE': 3, 'CDE': 1}\n",
      "L3: {'ABC': 2, 'ABD': 3, 'ABE': 4, 'ACE': 2, 'ADE': 3, 'BCD': 2, 'BCE': 3, 'BDE': 3}\n",
      "=============\n",
      "C4: {'ABCE': 2, 'ABDE': 3}\n",
      "L4: {'ABCE': 2, 'ABDE': 3}\n",
      "=============\n",
      "C5: {}\n",
      "L5: {}\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "data = ['ABDE', 'BCE', 'ABDE', 'ABCE', 'ABCDE', 'BCD']\n",
    "apriorisolver = AprioriSolver(data, minsup=2)\n",
    "apriorisolver.apriori()\n",
    "apriorisolver.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 6,\n",
       " 'BC': 4,\n",
       " 'BD': 4,\n",
       " 'BE': 5,\n",
       " 'ABE': 4,\n",
       " 'BCD': 2,\n",
       " 'BCE': 3,\n",
       " 'ABCE': 2,\n",
       " 'ABDE': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriorisolver.get_closed_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BCD': 2, 'ABCE': 2, 'ABDE': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriorisolver.get_maximal_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Apriori Process:\n",
      "C1: {'1': 4, '2': 4, '3': 3, '4': 2, '5': 3, '6': 3, '7': 4, '8': 1, '9': 5, 'A': 2, 'B': 1}\n",
      "L1: {'1': 4, '2': 4, '7': 4, '9': 5}\n",
      "=============\n",
      "C2: {'12': 0, '17': 1, '19': 1, '27': 3, '29': 4, '79': 4}\n",
      "L2: {'29': 4, '79': 4}\n",
      "=============\n",
      "C3: {}\n",
      "L3: {}\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "data = [\"136A\", '136A', '1479', '2479', '2579', '2579', '2589', '136B']\n",
    "apriorisolver = AprioriSolver(data, minsup=4)\n",
    "apriorisolver.apriori()\n",
    "apriorisolver.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AHCSolver:\n",
    "    def __init__(self, data: pd.DataFrame, dist_type=\"MIN\"):\n",
    "        self.data = data\n",
    "        self.dist_type = dist_type\n",
    "        self.history = [data]\n",
    "\n",
    "    def _find_max(self, table):\n",
    "        max_value = table.values.max()\n",
    "        max_index = table.values.argmax()\n",
    "        max_row, max_col = divmod(max_index, table.shape[1])\n",
    "        max_index_label = table.index[max_row]\n",
    "        max_column_label = table.columns[max_col]\n",
    "\n",
    "        return max_value, max_index_label, max_column_label\n",
    "\n",
    "    def _merge_clusters(self, table: pd.DataFrame, c1, c2):\n",
    "        new_c = c1 + c2\n",
    "        \n",
    "        other_cs = table.index[(table.index != c1) & (table.index != c2)].to_list()\n",
    "        new_labels = other_cs + [new_c]\n",
    "        new_table = pd.DataFrame(table, columns=new_labels, index=new_labels)\n",
    "\n",
    "        for column in new_table.columns.to_list():\n",
    "            if column == new_c:\n",
    "                new_table.loc[[new_c], [column]] = -np.inf\n",
    "                continue\n",
    "            if self.dist_type == \"MIN\":\n",
    "                new_val = table.loc[[column], [c1, c2]].values.max()\n",
    "            elif self.dist_type == \"MAX\":\n",
    "                new_val = table.loc[[column], [c1, c2]].values.min()\n",
    "\n",
    "            new_table.loc[[new_c], [column]] = new_val\n",
    "        \n",
    "        new_table.loc[:, [new_c]] = new_table.loc[[new_c], :].values.reshape((len(new_labels), 1))\n",
    "        return new_table\n",
    "        \n",
    "\n",
    "    def ahc(self):\n",
    "        n_clusters = len(self.data)\n",
    "        while n_clusters > 2:\n",
    "            _, c1, c2 = self._find_max(self.history[-1])\n",
    "\n",
    "            new_table = self._merge_clusters(self.history[-1], c1, c2)\n",
    "            self.history.append(new_table)\n",
    "\n",
    "            n_clusters -= 1\n",
    "\n",
    "    def print_history(self):\n",
    "        print(\"History of merging:\")\n",
    "        for table in self.history:\n",
    "            print(table)\n",
    "            print(\"=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(p1,)</th>\n",
       "      <th>(p2,)</th>\n",
       "      <th>(p3,)</th>\n",
       "      <th>(p4,)</th>\n",
       "      <th>(p5,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(p1,)</th>\n",
       "      <td>-inf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p2,)</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p3,)</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p4,)</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p5,)</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       (p1,)  (p2,)  (p3,)  (p4,)  (p5,)\n",
       "(p1,)   -inf   0.10   0.41   0.55   0.35\n",
       "(p2,)   0.10   -inf   0.64   0.47   0.98\n",
       "(p3,)   0.41   0.64   -inf   0.44   0.85\n",
       "(p4,)   0.55   0.47   0.44   -inf   0.76\n",
       "(p5,)   0.35   0.98   0.85   0.76   -inf"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array([\n",
    "    [1.0, 0.1, 0.41, 0.55, 0.35],\n",
    "    [0, 1.0, 0.64, 0.47, 0.98],\n",
    "    [0, 0, 1.0, 0.44, 0.85],\n",
    "    [0, 0, 0, 1.0, 0.76],\n",
    "    [0, 0, 0, 0, 1.0]\n",
    "])\n",
    "\n",
    "data_array += data_array.T\n",
    "data_array[np.eye(data_array.shape[0], dtype=bool)] = -np.inf\n",
    "data_array\n",
    "\n",
    "labels = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "labels = [(x,) for x in labels]\n",
    "data = pd.DataFrame(data_array, index=labels, columns=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programs\\x64\\conda\\envs\\ml_stuff\\lib\\site-packages\\pandas\\core\\common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n",
      "c:\\programs\\x64\\conda\\envs\\ml_stuff\\lib\\site-packages\\pandas\\core\\common.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = np.asarray(values, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "ahcsolver = AHCSolver(data, dist_type=\"MAX\")\n",
    "ahcsolver.ahc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of merging:\n",
      "       (p1,)  (p2,)  (p3,)  (p4,)  (p5,)\n",
      "(p1,)   -inf   0.10   0.41   0.55   0.35\n",
      "(p2,)   0.10   -inf   0.64   0.47   0.98\n",
      "(p3,)   0.41   0.64   -inf   0.44   0.85\n",
      "(p4,)   0.55   0.47   0.44   -inf   0.76\n",
      "(p5,)   0.35   0.98   0.85   0.76   -inf\n",
      "=======================\n",
      "          (p1,)  (p3,)  (p4,)  (p2, p5)\n",
      "(p1,)      -inf   0.41   0.55      0.10\n",
      "(p3,)      0.41   -inf   0.44      0.64\n",
      "(p4,)      0.55   0.44   -inf      0.47\n",
      "(p2, p5)   0.10   0.64   0.47      -inf\n",
      "=======================\n",
      "              (p1,)  (p4,)  (p3, p2, p5)\n",
      "(p1,)          -inf   0.55          0.10\n",
      "(p4,)          0.55   -inf          0.44\n",
      "(p3, p2, p5)   0.10   0.44          -inf\n",
      "=======================\n",
      "              (p3, p2, p5)  (p1, p4)\n",
      "(p3, p2, p5)          -inf       0.1\n",
      "(p1, p4)               0.1      -inf\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "ahcsolver.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml_stuff')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e375afa3077a0e385e787b2faa1f8fef2fe9be2c8e0ccb32dfa53213e5158247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
