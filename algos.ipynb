{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from itertools import combinations\n",
    "from functools import cmp_to_key\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cmp_to_key\n",
    "def _itemset_str_comparator(a:str, b: str):\n",
    "        if len(a) < len(b):\n",
    "            return -1\n",
    "        if len(a) > len(b):\n",
    "            return 1\n",
    "\n",
    "        if a < b:\n",
    "            return -1\n",
    "        if a > b:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AprioriSolver:\n",
    "    def __init__(self, data: list, minsup: int):\n",
    "        self.data = [set(str(x)) for x in data]\n",
    "        self.minsup = minsup\n",
    "        self._unique_attributes = set.union(*self.data)\n",
    "\n",
    "    def _support(self, itemset: set):\n",
    "        res = 0\n",
    "        for transaction in self.data:\n",
    "            if itemset.issubset(transaction):\n",
    "                res += 1\n",
    "        return res\n",
    "\n",
    "    def _freq_itemsets_bruteforce(self, size=1):\n",
    "        res = []\n",
    "        for combo in combinations(self._unique_attributes, size):\n",
    "            itemset = set(combo)\n",
    "            if self._support(itemset) >= self.minsup:\n",
    "                res.append(itemset)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def apriori_gen(self, L_k1, k):\n",
    "        C_k = []\n",
    "        for p in L_k1:\n",
    "            for q in L_k1:\n",
    "                if k > 2 and list(p)[:k-2] != list(q)[:k-2]:\n",
    "                    continue\n",
    "                if k > 1 and list(p)[k-2] >= list(q)[k-2]:\n",
    "                    continue\n",
    "                C_k.append(set.union(p, q))\n",
    "\n",
    "        bad_cs = []\n",
    "        for c in C_k:\n",
    "            for item in c:\n",
    "                subset = c.difference({item})\n",
    "                if subset not in L_k1:\n",
    "                    bad_cs.append(c)\n",
    "\n",
    "        for bad_c in bad_cs:\n",
    "            C_k.remove(bad_c)\n",
    "\n",
    "        return C_k\n",
    "\n",
    "    def apriori(self, verbose=False):\n",
    "        L = [None, self._freq_itemsets_bruteforce()]\n",
    "        C = [None, [{x} for x in self._unique_attributes]]\n",
    "        k = 2\n",
    "        while len(L[k-1]) > 0:\n",
    "            C_k = self.apriori_gen(L[k-1], k)\n",
    "            L_k = []\n",
    "\n",
    "            for c in C_k:\n",
    "                if self._support(c) >= self.minsup:\n",
    "                    L_k.append(c)\n",
    "\n",
    "            L.append(L_k)\n",
    "            C.append(C_k)\n",
    "\n",
    "            k += 1\n",
    "\n",
    "        self.Ls = L\n",
    "        self.Cs = C\n",
    "\n",
    "    def print_report(self):\n",
    "        print(\"Main Apriori Process:\")\n",
    "        for i in range(1, len(self.Ls)):\n",
    "            C_dict, L_dict = dict(), dict()\n",
    "            for c in self.Cs[i]:\n",
    "                C_dict[\"\".join(sorted(c))] = self._support(c)\n",
    "            for l in self.Ls[i]:\n",
    "                L_dict[\"\".join(sorted(l))] = self._support(l)\n",
    "\n",
    "            keys = list(sorted(C_dict.keys()))\n",
    "            C_dict = {key: C_dict[key] for key in keys}\n",
    "\n",
    "            keys = list(sorted(L_dict.keys()))\n",
    "            L_dict = {key: L_dict[key] for key in keys}\n",
    "\n",
    "            print(f\"C{i}: {C_dict}\")\n",
    "            print(f\"L{i}: {L_dict}\")\n",
    "            print(\"=============\")\n",
    "\n",
    "    def _format_itemset_list_as_dict(self, l: list):\n",
    "        res_dict = dict()\n",
    "        for c in l:\n",
    "            res_dict[\"\".join(sorted(c))] = self._support(c)\n",
    "\n",
    "        keys = list(sorted(res_dict.keys(), key=_itemset_str_comparator))\n",
    "        res_dict = {key: res_dict[key] for key in keys}\n",
    "        return res_dict\n",
    "\n",
    "    def _is_superset_in_list(self, s: set, l: list):\n",
    "        for elem in l:\n",
    "            if elem.issuperset(s):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def get_maximal_frequent(self):\n",
    "        result = []\n",
    "        for i in range(1, len(self.Ls)-1):\n",
    "            for itemset in self.Ls[i]:\n",
    "                if not self._is_superset_in_list(itemset, self.Ls[i+1]):\n",
    "                    result.append(itemset)\n",
    "        result.extend(self.Ls[-1])\n",
    "        result = self._format_itemset_list_as_dict(result)\n",
    "        return result\n",
    "        \n",
    "\n",
    "    def get_closed_frequent(self):\n",
    "        result = []\n",
    "        for i in range(1, len(self.Ls)-1):\n",
    "            for itemset in self.Ls[i]:\n",
    "                good = True\n",
    "                for upper in self.Ls[i+1]:\n",
    "                    if upper.issuperset(itemset) and self._support(itemset) == self._support(upper):\n",
    "                        good = False\n",
    "                        break\n",
    "                if good:\n",
    "                    result.append(itemset)\n",
    "        result.extend(self.Ls[-1])\n",
    "        result = self._format_itemset_list_as_dict(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Apriori Process:\n",
      "C1: {'A': 4, 'B': 6, 'C': 4, 'D': 4, 'E': 5}\n",
      "L1: {'A': 4, 'B': 6, 'C': 4, 'D': 4, 'E': 5}\n",
      "=============\n",
      "C2: {'AB': 4, 'AC': 2, 'AD': 3, 'AE': 4, 'BC': 4, 'BD': 4, 'BE': 5, 'CD': 2, 'CE': 3, 'DE': 3}\n",
      "L2: {'AB': 4, 'AC': 2, 'AD': 3, 'AE': 4, 'BC': 4, 'BD': 4, 'BE': 5, 'CD': 2, 'CE': 3, 'DE': 3}\n",
      "=============\n",
      "C3: {'ABC': 2, 'ABD': 3, 'ABE': 4, 'ACD': 1, 'ACE': 2, 'ADE': 3, 'BCD': 2, 'BCE': 3, 'BDE': 3, 'CDE': 1}\n",
      "L3: {'ABC': 2, 'ABD': 3, 'ABE': 4, 'ACE': 2, 'ADE': 3, 'BCD': 2, 'BCE': 3, 'BDE': 3}\n",
      "=============\n",
      "C4: {'ABCE': 2, 'ABDE': 3}\n",
      "L4: {'ABCE': 2, 'ABDE': 3}\n",
      "=============\n",
      "C5: {}\n",
      "L5: {}\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "data = ['ABDE', 'BCE', 'ABDE', 'ABCE', 'ABCDE', 'BCD']\n",
    "apriorisolver = AprioriSolver(data, minsup=2)\n",
    "apriorisolver.apriori()\n",
    "apriorisolver.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 6,\n",
       " 'BC': 4,\n",
       " 'BD': 4,\n",
       " 'BE': 5,\n",
       " 'ABE': 4,\n",
       " 'BCD': 2,\n",
       " 'BCE': 3,\n",
       " 'ABCE': 2,\n",
       " 'ABDE': 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriorisolver.get_closed_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BCD': 2, 'ABCE': 2, 'ABDE': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriorisolver.get_maximal_frequent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Apriori Process:\n",
      "C1: {'1': 4, '2': 4, '3': 3, '4': 2, '5': 3, '6': 3, '7': 4, '8': 1, '9': 5, 'A': 2, 'B': 1}\n",
      "L1: {'1': 4, '2': 4, '7': 4, '9': 5}\n",
      "=============\n",
      "C2: {'12': 0, '17': 1, '19': 1, '27': 3, '29': 4, '79': 4}\n",
      "L2: {'29': 4, '79': 4}\n",
      "=============\n",
      "C3: {}\n",
      "L3: {}\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "data = [\"136A\", '136A', '1479', '2479', '2579', '2579', '2589', '136B']\n",
    "apriorisolver = AprioriSolver(data, minsup=4)\n",
    "apriorisolver.apriori()\n",
    "apriorisolver.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(a, b, measure_name):\n",
    "    \"\"\" Compute the dist or similarity between two sets \"\"\"\n",
    "    # a b are numpy arrays\n",
    "    if measure_name == 'jaccard':\n",
    "        # only consider where both are 1\n",
    "        intersection = np.logical_and(a, b)\n",
    "        union = np.logical_or(a, b)\n",
    "        return - intersection.sum() / union.sum()\n",
    "    elif measure_name == 'euclidean':\n",
    "        return np.linalg.norm(np.array(a) - np.array(b))\n",
    "    elif measure_name == 'cosine':\n",
    "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def compute_distance_matrix(data, measure_name):\n",
    "    \"\"\" Compute and print the distance matrix for the data \"\"\"\n",
    "    data = MultiLabelBinarizer().fit_transform(data)\n",
    "    labels = [('T'+str(i+1), ) for i in range(len(data))]\n",
    "    square_distance_matrix = np.zeros((len(data), len(data)))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            if i == j:\n",
    "                square_distance_matrix[i][j] = 0\n",
    "            else:\n",
    "                square_distance_matrix[i][j] = measure(data[i], data[j], measure_name)\n",
    "    \n",
    "    square_distance_matrix[np.eye(square_distance_matrix.shape[0], dtype=bool)] = np.inf\n",
    "    square_distance_matrix *= -1\n",
    "    df = pd.DataFrame(square_distance_matrix, columns=labels, index=labels)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AHCSolver:\n",
    "    def __init__(self, data: pd.DataFrame, dist_type=\"MIN\"):\n",
    "        self.data = data\n",
    "        self.dist_type = dist_type\n",
    "        self.history = [data]\n",
    "\n",
    "    def _find_max(self, table):\n",
    "        max_value = table.values.max()\n",
    "        max_index = table.values.argmax()\n",
    "        max_row, max_col = divmod(max_index, table.shape[1])\n",
    "        max_index_label = table.index[max_row]\n",
    "        max_column_label = table.columns[max_col]\n",
    "\n",
    "        return max_value, max_index_label, max_column_label\n",
    "\n",
    "    def _merge_clusters(self, table: pd.DataFrame, c1, c2):\n",
    "        new_c = c1 + c2\n",
    "        \n",
    "        other_cs = table.index[(table.index != c1) & (table.index != c2)].to_list()\n",
    "        new_labels = other_cs + [new_c]\n",
    "        new_table = pd.DataFrame(table, columns=new_labels, index=new_labels)\n",
    "\n",
    "        for column in new_table.columns.to_list():\n",
    "            if column == new_c:\n",
    "                new_table.loc[[new_c], [column]] = -np.inf\n",
    "                continue\n",
    "            if self.dist_type == \"MIN\":\n",
    "                new_val = table.loc[[column], [c1, c2]].values.max()\n",
    "            elif self.dist_type == \"MAX\":\n",
    "                new_val = table.loc[[column], [c1, c2]].values.min()\n",
    "\n",
    "            new_table.loc[[new_c], [column]] = new_val\n",
    "        \n",
    "        new_table.loc[:, [new_c]] = new_table.loc[[new_c], :].values.reshape((len(new_labels), 1))\n",
    "        return new_table\n",
    "        \n",
    "\n",
    "    def ahc(self):\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            n_clusters = len(self.data)\n",
    "            while n_clusters > 2:\n",
    "                _, c1, c2 = self._find_max(self.history[-1])\n",
    "\n",
    "                new_table = self._merge_clusters(self.history[-1], c1, c2)\n",
    "                self.history.append(new_table)\n",
    "\n",
    "                n_clusters -= 1\n",
    "\n",
    "    def print_history(self):\n",
    "        print(\"History of merging:\")\n",
    "        for table in self.history:\n",
    "            print(table)\n",
    "            print(\"=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(p1,)</th>\n",
       "      <th>(p2,)</th>\n",
       "      <th>(p3,)</th>\n",
       "      <th>(p4,)</th>\n",
       "      <th>(p5,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(p1,)</th>\n",
       "      <td>-inf</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p2,)</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p3,)</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p4,)</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(p5,)</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       (p1,)  (p2,)  (p3,)  (p4,)  (p5,)\n",
       "(p1,)   -inf   0.10   0.41   0.55   0.35\n",
       "(p2,)   0.10   -inf   0.64   0.47   0.98\n",
       "(p3,)   0.41   0.64   -inf   0.44   0.85\n",
       "(p4,)   0.55   0.47   0.44   -inf   0.76\n",
       "(p5,)   0.35   0.98   0.85   0.76   -inf"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array([\n",
    "    [1.0, 0.1, 0.41, 0.55, 0.35],\n",
    "    [0, 1.0, 0.64, 0.47, 0.98],\n",
    "    [0, 0, 1.0, 0.44, 0.85],\n",
    "    [0, 0, 0, 1.0, 0.76],\n",
    "    [0, 0, 0, 0, 1.0]\n",
    "])\n",
    "\n",
    "data_array += data_array.T\n",
    "data_array[np.eye(data_array.shape[0], dtype=bool)] = -np.inf\n",
    "data_array\n",
    "\n",
    "labels = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\"]\n",
    "labels = [(x,) for x in labels]\n",
    "data = pd.DataFrame(data_array, index=labels, columns=labels)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ahcsolver = AHCSolver(data, dist_type=\"MAX\")\n",
    "ahcsolver.ahc()\n",
    "ahcsolver.print_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of merging:\n",
      "          (T1,)     (T2,)     (T3,)     (T4,)     (T5,)     (T6,)\n",
      "(T1,)      -inf  0.833333  0.666667  0.142857  0.285714  0.125000\n",
      "(T2,)  0.833333      -inf  0.800000 -0.000000  0.142857 -0.000000\n",
      "(T3,)  0.666667  0.800000      -inf -0.000000 -0.000000 -0.000000\n",
      "(T4,)  0.142857 -0.000000 -0.000000      -inf  0.666667  0.666667\n",
      "(T5,)  0.285714  0.142857 -0.000000  0.666667      -inf  0.500000\n",
      "(T6,)  0.125000 -0.000000 -0.000000  0.666667  0.500000      -inf\n",
      "=======================\n",
      "          (T3,)     (T4,)     (T5,)     (T6,)  (T1, T2)\n",
      "(T3,)      -inf -0.000000 -0.000000 -0.000000  0.800000\n",
      "(T4,)      -0.0      -inf  0.666667  0.666667  0.142857\n",
      "(T5,)      -0.0  0.666667      -inf  0.500000  0.285714\n",
      "(T6,)      -0.0  0.666667  0.500000      -inf  0.125000\n",
      "(T1, T2)    0.8  0.142857  0.285714  0.125000      -inf\n",
      "=======================\n",
      "                 (T4,)     (T5,)     (T6,)  (T3, T1, T2)\n",
      "(T4,)             -inf  0.666667  0.666667      0.142857\n",
      "(T5,)         0.666667      -inf  0.500000      0.285714\n",
      "(T6,)         0.666667  0.500000      -inf      0.125000\n",
      "(T3, T1, T2)  0.142857  0.285714  0.125000          -inf\n",
      "=======================\n",
      "                 (T6,)  (T3, T1, T2)  (T4, T5)\n",
      "(T6,)             -inf      0.125000  0.666667\n",
      "(T3, T1, T2)  0.125000          -inf  0.285714\n",
      "(T4, T5)      0.666667      0.285714      -inf\n",
      "=======================\n",
      "              (T3, T1, T2)  (T6, T4, T5)\n",
      "(T3, T1, T2)          -inf      0.285714\n",
      "(T6, T4, T5)      0.285714          -inf\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "raw_data = [\n",
    "    ['A', 'B', 'C', 'D', 'E', 'F'],\n",
    "    ['A', 'B', 'C', 'D', 'E'],\n",
    "    ['B', 'C', 'D', 'E'],\n",
    "    ['F', 'G'],\n",
    "    ['A', 'F', 'G'],\n",
    "    ['H', 'I']\n",
    "]\n",
    "\n",
    "matrix_data = compute_distance_matrix(data, 'jaccard')\n",
    "solver = AHCSolver(matrix_data, dist_type=\"MIN\")\n",
    "solver.ahc()\n",
    "solver.print_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml_stuff')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e375afa3077a0e385e787b2faa1f8fef2fe9be2c8e0ccb32dfa53213e5158247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
